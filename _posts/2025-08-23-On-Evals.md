---
layout: post
title: On LLM Evals
---

LLMs hallucinate.Your job is to ensure they don’t embarrass you, your company, or your brand.

# Table of contents
1. [Introduction](#introduction)
2. [Choosing the right LLM](#part1)
    1. [Sub paragraph](#subparagraph1)
3. [Another paragraph](#paragraph2)

## Introduction <a name="introduction"></a>
- AI evals are like unit tests for agents.
- Difference between software testing vs AI evals:
  - Software testing & unit tests are deterministic. LLM agents are non-deterministic, with multiple possible paths.
  - Integration tests rely on code/docs, but improving agents relies on data.

## Part 1 - Choosing the right LLM <a name="part1"></a>
- Start with **requirements** along these dimensions
  - **Accuracy**: example >90% ideal in legal contexts.
  - **Latency**: Medium–low is acceptable for offline jobs.
  - **Cost**: Less sensitive initially since manual legal review is expensive.
  - **Context length**: for example Must handle long docs (≈20K–1M tokens).
  - **Throughput (QPM)**: Size for expected query volume.
  - **Grounding**: Model should cite source contract text.
- Some **benchmarks**you could use , typically published by models -
  - Language understanding
  - Q&A
  - Document classification
  - Reasoning (planning, chain-of-thought)
  - Tool usage (email, APIs, CRM)

- **Model Selection** 
Use published evals/model cards (e.g., a “model matrix”) to compare options.
Example: O3 High mini may offer a strong balance of accuracy, latency, and cost.

### Sub paragraph <a name="subparagraph1"></a>
This is a sub paragraph, formatted in heading 3 style

## Another paragraph <a name="paragraph2"></a>
The second paragraph text

